% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/AClass_230815_2.R
\name{nano.cal_model}
\alias{nano.cal_model}
\title{Train class-wise recalibration models for prediction confidence}
\usage{
nano.cal_model(cal_labels.df, method = c("glm", "glmnet"))
}
\arguments{
\item{cal_labels.df}{Data frame. Must contain columns: "obs" for ground truth, "Class" for multi-class prediction made from classifier, "Sample" for Names for where the Avg_Probability originated, and "Avg_Probability" for average probability predicted from the classifier.}

\item{method}{Algorithm to use for score recalibration. Options are \code{glm} or \code{glmnet}}
}
\value{
Named list of trained calibration models, one per class. Includes original calibration data under \verb{$Data}.
}
\description{
Fits regression models to recalibrate classifier scores for each class using true labels and predicted probabilities, inspired by Capper et al. (2018) doi: 10.1038/nature26000. Supports both \code{glm} and \code{glmnet} methods.
It is recommended to use a held-out validation set or cross-validation for calibration, to avoid data leakage and overfitting.
}
\examples{
cal_models <- nano.cal_model(cal_labels.df, method = "glm")
}
